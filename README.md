# ğŸ¤– Smart Research Assistant (Offline + GPU Support)

An intelligent, GPU-accelerated research assistant that summarizes academic documents and answers questions from them â€” all offline! Built with ğŸ’¡ PyTorch, ğŸ¤— Transformers, and ğŸ§  NLP.

---

## ğŸš€ Features

- ğŸ” **Automatic Text Summarization**
- ğŸ¤” **Contextual Question Answering (QA)**
- âš¡ **GPU Acceleration Support**
- ğŸ“„ PDF File Upload and Extraction
- ğŸ§  Local LLM Inference (No API Required)
- âœ… Streamlit UI for ease of use

---

## ğŸ¯ Use Case

This project is ideal for:
- Students reading research papers
- Researchers exploring large PDFs
- Offline environments with no internet access
- Developers experimenting with summarization & QA pipelines

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technology                         |
|--------------|------------------------------------|
| Frontend     | `Streamlit`                        |
| Backend      | `Transformers`, `PyTorch`          |
| PDF Parsing  | `PyMuPDF (fitz)`                   |
| Summarization| `Falconsai/text_summarization`     |
| QA Model     | `deepset/roberta-base-squad2`      |

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/<your-username>/smart_assistant.git
cd smart_assistant
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
streamlit run main.py
